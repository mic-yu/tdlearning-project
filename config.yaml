mode: "wandb_sweep" #or "single_run" #or "sweep"
path: "./data/n_eps-100-env-base_agent_env_2025-08-13_16-12-02.pkl" #training data path
model_storage_dir: "models"
chtc: True
max_k: 10
train_val_test_split: [0.6, 0.2, 0.2]
num_epochs: 5
train_forward_sig: True #Manually pass outputs of model during training through a sigmoid layer inside script. 
                        #It is always turned off for the model.
eval_frequency: 5 #Evaluation will happen every eval_frequency epochs during training
train_loss_frequency: 1000 #Report running avg loss after this inteverval of steps
loss_fn: "MSE"
optimizer: "Adam"

wandb:
  entity: "dpinchuk-university-of-wisconsin-madison"
  project: "test_sweep_2" #"td_test"

wandb_sweep:
  name: "test_4"
  n_layers: 5
  sweep_id: "pvf8ivxa"

optuna_settings:
  study_name: "tdgoal_h100_ep100_epoch200"
  db_dir: "databases"
  db_name: "tdgoal_h100_ep100_epoch200.db"

  num_trials: 1
  n_startup_trials: 10

search_space:
  n_layers_range: [1, 5]
  num_neurons_range: [8, 64] #number of neurons in each layer
  bs_range: [32, 512] #batch size range
  bs_step: 32
  lr_range: [1e-5, 1e-2]
  target_update_frequency_range: [1000, 10000] #steps. 
  tuf_step: 1000

single_run:
  n_layers: 2 #hidden layers
  hidden_sizes: [8, 64] #number of neurons in each layer
  bs:  200
  lr: 3e-3
  target_update_frequency: 9000 #steps. 


